{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5e7e48",
   "metadata": {
    "_cell_guid": "b7e0e8cb-9566-40b9-af5a-2d9c3d783437",
    "_uuid": "468f563e-3d4d-4f25-9179-2565cecb2273",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:27:53.894863Z",
     "iopub.status.busy": "2025-09-20T23:27:53.894592Z",
     "iopub.status.idle": "2025-09-20T23:28:07.530473Z",
     "shell.execute_reply": "2025-09-20T23:28:07.529887Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 13.642888,
     "end_time": "2025-09-20T23:28:07.531801",
     "exception": false,
     "start_time": "2025-09-20T23:27:53.888913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be31483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T23:28:07.541379Z",
     "iopub.status.busy": "2025-09-20T23:28:07.540978Z",
     "iopub.status.idle": "2025-09-20T23:29:03.883860Z",
     "shell.execute_reply": "2025-09-20T23:29:03.883073Z"
    },
    "papermill": {
     "duration": 56.348957,
     "end_time": "2025-09-20T23:29:03.885322",
     "exception": false,
     "start_time": "2025-09-20T23:28:07.536365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Collecting torch\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.8.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.8.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (184.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.1/184.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: sympy, torch, torchvision\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.1\r\n",
      "    Uninstalling sympy-1.13.1:\r\n",
      "      Successfully uninstalled sympy-1.13.1\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0+cpu which is incompatible.\r\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0+cpu which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed sympy-1.13.3 torch-2.8.0+cpu torchvision-0.23.0+cpu\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision --upgrade --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc0b29b",
   "metadata": {
    "_cell_guid": "74af958a-43f3-48bc-81d0-e5ccc35d94c4",
    "_uuid": "0408892f-6400-47be-a112-e15aa74dc3d5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:03.900271Z",
     "iopub.status.busy": "2025-09-20T23:29:03.899696Z",
     "iopub.status.idle": "2025-09-20T23:29:03.958293Z",
     "shell.execute_reply": "2025-09-20T23:29:03.957666Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.067031,
     "end_time": "2025-09-20T23:29:03.959371",
     "exception": false,
     "start_time": "2025-09-20T23:29:03.892340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True if str(device) == \"cuda\" else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb596f5",
   "metadata": {
    "_cell_guid": "38aefcd1-d252-486a-8667-6d4aba0492be",
    "_uuid": "70c6290b-65bc-471c-b162-8452cae9b698",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:03.974197Z",
     "iopub.status.busy": "2025-09-20T23:29:03.973957Z",
     "iopub.status.idle": "2025-09-20T23:29:03.977430Z",
     "shell.execute_reply": "2025-09-20T23:29:03.976740Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01234,
     "end_time": "2025-09-20T23:29:03.978558",
     "exception": false,
     "start_time": "2025-09-20T23:29:03.966218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainroot = '/kaggle/input/dog-breed-identification/train'\n",
    "testroot = '/kaggle/input/dog-breed-identification/test'\n",
    "sample = '/kaggle/input/dog-breed-identification/sample_submission.csv'\n",
    "labelsroot = '/kaggle/input/dog-breed-identification/labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf281913",
   "metadata": {
    "_cell_guid": "b19501f2-1a91-4a34-afc0-5a9a277b182a",
    "_uuid": "2b49602a-8253-4eef-aa2c-81dcda05b154",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:03.992285Z",
     "iopub.status.busy": "2025-09-20T23:29:03.992066Z",
     "iopub.status.idle": "2025-09-20T23:29:04.533828Z",
     "shell.execute_reply": "2025-09-20T23:29:04.533224Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.550129,
     "end_time": "2025-09-20T23:29:04.535092",
     "exception": false,
     "start_time": "2025-09-20T23:29:03.984963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = pd.read_csv(sample).keys()[1:]\n",
    "breed2idx = { cls: i for i, cls in enumerate(class_names) }\n",
    "\n",
    "labels = pd.read_csv(labelsroot)\n",
    "labels = labels.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f92204",
   "metadata": {
    "_cell_guid": "05e3642b-a277-458c-9b07-3053e2118538",
    "_uuid": "d80940cd-481a-4430-a9dc-5678d1f4d0b4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:04.549490Z",
     "iopub.status.busy": "2025-09-20T23:29:04.549262Z",
     "iopub.status.idle": "2025-09-20T23:29:04.580123Z",
     "shell.execute_reply": "2025-09-20T23:29:04.579542Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.039332,
     "end_time": "2025-09-20T23:29:04.581237",
     "exception": false,
     "start_time": "2025-09-20T23:29:04.541905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000bec180eb18c7604dcecc8fe0dba07</th>\n",
       "      <td>boston_bull</td>\n",
       "      <td>/kaggle/input/dog-breed-identification/train/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001513dfcb2ffafc82cccf4d8bbaba97</th>\n",
       "      <td>dingo</td>\n",
       "      <td>/kaggle/input/dog-breed-identification/train/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001cdf01b096e06d78e9e5112d419397</th>\n",
       "      <td>pekinese</td>\n",
       "      <td>/kaggle/input/dog-breed-identification/train/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00214f311d5d2247d5dfe4fe24b2303d</th>\n",
       "      <td>bluetick</td>\n",
       "      <td>/kaggle/input/dog-breed-identification/train/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0021f9ceb3235effd7fcde7f7538ed62</th>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>/kaggle/input/dog-breed-identification/train/0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             breed  \\\n",
       "id                                                   \n",
       "000bec180eb18c7604dcecc8fe0dba07       boston_bull   \n",
       "001513dfcb2ffafc82cccf4d8bbaba97             dingo   \n",
       "001cdf01b096e06d78e9e5112d419397          pekinese   \n",
       "00214f311d5d2247d5dfe4fe24b2303d          bluetick   \n",
       "0021f9ceb3235effd7fcde7f7538ed62  golden_retriever   \n",
       "\n",
       "                                                                           filepath  \n",
       "id                                                                                   \n",
       "000bec180eb18c7604dcecc8fe0dba07  /kaggle/input/dog-breed-identification/train/0...  \n",
       "001513dfcb2ffafc82cccf4d8bbaba97  /kaggle/input/dog-breed-identification/train/0...  \n",
       "001cdf01b096e06d78e9e5112d419397  /kaggle/input/dog-breed-identification/train/0...  \n",
       "00214f311d5d2247d5dfe4fe24b2303d  /kaggle/input/dog-breed-identification/train/0...  \n",
       "0021f9ceb3235effd7fcde7f7538ed62  /kaggle/input/dog-breed-identification/train/0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = labels.copy()\n",
    "df[\"filepath\"] = df.index.map(lambda x: os.path.join(trainroot, x + \".jpg\"))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0983f89",
   "metadata": {
    "_cell_guid": "f72f0f70-6809-4d79-8ad4-734e130dac8b",
    "_uuid": "a354975b-3ced-47d4-a521-80bc6f664754",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:04.595994Z",
     "iopub.status.busy": "2025-09-20T23:29:04.595373Z",
     "iopub.status.idle": "2025-09-20T23:29:04.600945Z",
     "shell.execute_reply": "2025-09-20T23:29:04.600465Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013887,
     "end_time": "2025-09-20T23:29:04.601941",
     "exception": false,
     "start_time": "2025-09-20T23:29:04.588054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_transform = {\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size = 256),\n",
    "        transforms.CenterCrop(size = 224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size = 256),\n",
    "        transforms.RandomRotation(degrees = 30),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size = 224),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  \n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size = 256),\n",
    "        transforms.CenterCrop(size = 224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9307985b",
   "metadata": {
    "_cell_guid": "0da24d3e-9ae3-43fe-913c-09e818855f23",
    "_uuid": "e132c5f4-42d6-4e66-b496-35be6fc4fb6a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:04.616259Z",
     "iopub.status.busy": "2025-09-20T23:29:04.615548Z",
     "iopub.status.idle": "2025-09-20T23:29:04.620349Z",
     "shell.execute_reply": "2025-09-20T23:29:04.619815Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01289,
     "end_time": "2025-09-20T23:29:04.621346",
     "exception": false,
     "start_time": "2025-09-20T23:29:04.608456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Configure(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tran = None):\n",
    "        self.df = df\n",
    "        self.tran = tran\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['filepath'])\n",
    "        if self.tran:\n",
    "            image = self.tran(image)\n",
    "        label = breed2idx[row[\"breed\"]]\n",
    "        label = torch.tensor(label, dtype = torch.long)\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9acf8f8f",
   "metadata": {
    "_cell_guid": "6733bbb5-a9fe-4546-ba4d-bba5460f62c0",
    "_uuid": "032e0046-14e7-4a18-8e6a-6fb214402340",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:04.635039Z",
     "iopub.status.busy": "2025-09-20T23:29:04.634867Z",
     "iopub.status.idle": "2025-09-20T23:29:04.637688Z",
     "shell.execute_reply": "2025-09-20T23:29:04.637229Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010728,
     "end_time": "2025-09-20T23:29:04.638640",
     "exception": false,
     "start_time": "2025-09-20T23:29:04.627912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Configure(df = df, tran = img_transform['train'])\n",
    "val_dataset = Configure(df = df, tran = img_transform['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa00b7d2",
   "metadata": {
    "_cell_guid": "73184d58-9628-4efa-99f3-1aab0ad7a6e0",
    "_uuid": "91d4c97b-2453-49e1-a7bb-e0873e335c60",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:04.652401Z",
     "iopub.status.busy": "2025-09-20T23:29:04.652165Z",
     "iopub.status.idle": "2025-09-20T23:29:04.655846Z",
     "shell.execute_reply": "2025-09-20T23:29:04.655356Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011662,
     "end_time": "2025-09-20T23:29:04.656779",
     "exception": false,
     "start_time": "2025-09-20T23:29:04.645117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False, \n",
    "    num_workers = num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d87c549e",
   "metadata": {
    "_cell_guid": "b5753e39-6e36-4244-81a9-0932e5dc3a3b",
    "_uuid": "3c58e8e1-dda7-4954-9441-a3bf4eeb600a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:04.670509Z",
     "iopub.status.busy": "2025-09-20T23:29:04.670335Z",
     "iopub.status.idle": "2025-09-20T23:29:04.673094Z",
     "shell.execute_reply": "2025-09-20T23:29:04.672620Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010905,
     "end_time": "2025-09-20T23:29:04.674147",
     "exception": false,
     "start_time": "2025-09-20T23:29:04.663242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'valid': val_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6248d3a0",
   "metadata": {
    "_cell_guid": "4d688986-c508-4bb1-b585-af2ceaeaf48e",
    "_uuid": "bb344e77-28c5-415c-b26f-b206f2f9ef1c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:04.688113Z",
     "iopub.status.busy": "2025-09-20T23:29:04.687663Z",
     "iopub.status.idle": "2025-09-20T23:29:05.882939Z",
     "shell.execute_reply": "2025-09-20T23:29:05.882076Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.203648,
     "end_time": "2025-09-20T23:29:05.884297",
     "exception": false,
     "start_time": "2025-09-20T23:29:04.680649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 217MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "model_resnet = models.resnet50(pretrained = True)\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "in_features = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(in_features, 120)\n",
    "\n",
    "if use_cuda:\n",
    "    model_resnet = model_resnet.cuda()\n",
    "\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "751ae856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:05.899575Z",
     "iopub.status.busy": "2025-09-20T23:29:05.899352Z",
     "iopub.status.idle": "2025-09-20T23:29:07.565883Z",
     "shell.execute_reply": "2025-09-20T23:29:07.565082Z"
    },
    "papermill": {
     "duration": 1.675535,
     "end_time": "2025-09-20T23:29:07.567297",
     "exception": false,
     "start_time": "2025-09-20T23:29:05.891762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth\" to /root/.cache/torch/hub/checkpoints/xception-43020ad28.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (block1): Block(\n",
      "    (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rep): Sequential(\n",
      "      (0): SeparableConv2d(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): SeparableConv2d(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (block2): Block(\n",
      "    (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (block3): Block(\n",
      "    (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (block4): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block5): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block6): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block7): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block8): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block9): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block10): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block11): Block(\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (block12): Block(\n",
      "    (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rep): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (conv3): SeparableConv2d(\n",
      "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
      "    (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act3): ReLU(inplace=True)\n",
      "  (conv4): SeparableConv2d(\n",
      "    (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "    (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (bn4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act4): ReLU(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_xception = timm.create_model('xception', pretrained = True)\n",
    "\n",
    "for param in model_xception.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_xception.fc = nn.Linear(model_xception.fc.in_features, 120)\n",
    "\n",
    "if use_cuda:\n",
    "    model_xception = model_xception.cuda()\n",
    "\n",
    "print(model_xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43238e7e",
   "metadata": {
    "_cell_guid": "dd5968e7-2a56-4eb3-88b3-0933754fc7b9",
    "_uuid": "52f425aa-9dd4-4671-afa6-3f2f41b18787",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:07.583330Z",
     "iopub.status.busy": "2025-09-20T23:29:07.583043Z",
     "iopub.status.idle": "2025-09-20T23:29:07.587460Z",
     "shell.execute_reply": "2025-09-20T23:29:07.586897Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013312,
     "end_time": "2025-09-20T23:29:07.588442",
     "exception": false,
     "start_time": "2025-09-20T23:29:07.575130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion_resnet = nn.CrossEntropyLoss()\n",
    "grad_parameters_resnet = filter(lambda p: p.requires_grad, model_resnet.parameters())\n",
    "optimizer_resnet = torch.optim.SGD(grad_parameters_resnet, lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c2a548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:07.603831Z",
     "iopub.status.busy": "2025-09-20T23:29:07.603460Z",
     "iopub.status.idle": "2025-09-20T23:29:07.607551Z",
     "shell.execute_reply": "2025-09-20T23:29:07.607026Z"
    },
    "papermill": {
     "duration": 0.012845,
     "end_time": "2025-09-20T23:29:07.608553",
     "exception": false,
     "start_time": "2025-09-20T23:29:07.595708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion_xception = nn.CrossEntropyLoss()\n",
    "grad_parameters_xception = filter(lambda p: p.requires_grad, model_xception.parameters())\n",
    "optimizer_xception = torch.optim.SGD(grad_parameters_xception, lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "876bea13",
   "metadata": {
    "_cell_guid": "ab759706-6770-4e21-8efc-eb2d97b98ffd",
    "_uuid": "139c4819-1445-4713-814f-9370325804a8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:07.623879Z",
     "iopub.status.busy": "2025-09-20T23:29:07.623514Z",
     "iopub.status.idle": "2025-09-20T23:29:07.629719Z",
     "shell.execute_reply": "2025-09-20T23:29:07.629209Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014901,
     "end_time": "2025-09-20T23:29:07.630715",
     "exception": false,
     "start_time": "2025-09-20T23:29:07.615814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    valid_loss_min = np.Inf \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Epoch: %d \\tBatch: %d \\tTraining Loss: %.6f' %(epoch, batch_idx + 1, train_loss))\n",
    "\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "        print('Epoch: {} \\tTraining Loss: {:.4f} \\tValidation Loss: {:.4f}'.format(epoch, train_loss, valid_loss))\n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print('BOOM! Validation loss decreased ({:.4f} --> {:.4f}).  Saving model...'.format(valid_loss_min,valid_loss))\n",
    "            valid_loss_min = valid_loss    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20295606",
   "metadata": {
    "_cell_guid": "d906aea3-b8a5-4039-814a-39e74c7bfc23",
    "_uuid": "81830e8c-edca-4e36-92f5-e4f269c1fa53",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-20T23:29:07.645978Z",
     "iopub.status.busy": "2025-09-20T23:29:07.645811Z",
     "iopub.status.idle": "2025-09-21T02:18:47.507263Z",
     "shell.execute_reply": "2025-09-21T02:18:47.506472Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 10179.90167,
     "end_time": "2025-09-21T02:18:47.539630",
     "exception": false,
     "start_time": "2025-09-20T23:29:07.637960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 4.914670\n",
      "Epoch: 1 \tBatch: 101 \tTraining Loss: 4.674582\n",
      "Epoch: 1 \tBatch: 201 \tTraining Loss: 4.498480\n",
      "Epoch: 1 \tBatch: 301 \tTraining Loss: 4.330291\n",
      "Epoch: 1 \tBatch: 401 \tTraining Loss: 4.166200\n",
      "Epoch: 1 \tBatch: 501 \tTraining Loss: 4.023600\n",
      "Epoch: 1 \tTraining Loss: 4.0124 \tValidation Loss: 2.6546\n",
      "BOOM! Validation loss decreased (inf --> 2.6546).  Saving model...\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 3.208431\n",
      "Epoch: 2 \tBatch: 101 \tTraining Loss: 3.184795\n",
      "Epoch: 2 \tBatch: 201 \tTraining Loss: 3.092531\n",
      "Epoch: 2 \tBatch: 301 \tTraining Loss: 3.006237\n",
      "Epoch: 2 \tBatch: 401 \tTraining Loss: 2.932922\n",
      "Epoch: 2 \tBatch: 501 \tTraining Loss: 2.857128\n",
      "Epoch: 2 \tTraining Loss: 2.8506 \tValidation Loss: 1.6608\n",
      "BOOM! Validation loss decreased (2.6546 --> 1.6608).  Saving model...\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 2.350254\n",
      "Epoch: 3 \tBatch: 101 \tTraining Loss: 2.461419\n",
      "Epoch: 3 \tBatch: 201 \tTraining Loss: 2.391841\n",
      "Epoch: 3 \tBatch: 301 \tTraining Loss: 2.357469\n",
      "Epoch: 3 \tBatch: 401 \tTraining Loss: 2.332847\n",
      "Epoch: 3 \tBatch: 501 \tTraining Loss: 2.288076\n",
      "Epoch: 3 \tTraining Loss: 2.2875 \tValidation Loss: 1.1214\n",
      "BOOM! Validation loss decreased (1.6608 --> 1.1214).  Saving model...\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 1.979203\n",
      "Epoch: 4 \tBatch: 101 \tTraining Loss: 2.074446\n",
      "Epoch: 4 \tBatch: 201 \tTraining Loss: 2.063793\n",
      "Epoch: 4 \tBatch: 301 \tTraining Loss: 2.039118\n",
      "Epoch: 4 \tBatch: 401 \tTraining Loss: 2.016185\n",
      "Epoch: 4 \tBatch: 501 \tTraining Loss: 1.996175\n",
      "Epoch: 4 \tTraining Loss: 2.0000 \tValidation Loss: 0.9527\n",
      "BOOM! Validation loss decreased (1.1214 --> 0.9527).  Saving model...\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 1.725095\n",
      "Epoch: 5 \tBatch: 101 \tTraining Loss: 1.871054\n",
      "Epoch: 5 \tBatch: 201 \tTraining Loss: 1.882904\n",
      "Epoch: 5 \tBatch: 301 \tTraining Loss: 1.871451\n",
      "Epoch: 5 \tBatch: 401 \tTraining Loss: 1.858765\n",
      "Epoch: 5 \tBatch: 501 \tTraining Loss: 1.839283\n",
      "Epoch: 5 \tTraining Loss: 1.8424 \tValidation Loss: 0.7616\n",
      "BOOM! Validation loss decreased (0.9527 --> 0.7616).  Saving model...\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 1.543087\n",
      "Epoch: 6 \tBatch: 101 \tTraining Loss: 1.747220\n",
      "Epoch: 6 \tBatch: 201 \tTraining Loss: 1.735364\n",
      "Epoch: 6 \tBatch: 301 \tTraining Loss: 1.732267\n",
      "Epoch: 6 \tBatch: 401 \tTraining Loss: 1.741745\n",
      "Epoch: 6 \tBatch: 501 \tTraining Loss: 1.729877\n",
      "Epoch: 6 \tTraining Loss: 1.7301 \tValidation Loss: 0.7020\n",
      "BOOM! Validation loss decreased (0.7616 --> 0.7020).  Saving model...\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 1.786790\n",
      "Epoch: 7 \tBatch: 101 \tTraining Loss: 1.682226\n",
      "Epoch: 7 \tBatch: 201 \tTraining Loss: 1.711416\n",
      "Epoch: 7 \tBatch: 301 \tTraining Loss: 1.683738\n",
      "Epoch: 7 \tBatch: 401 \tTraining Loss: 1.666422\n",
      "Epoch: 7 \tBatch: 501 \tTraining Loss: 1.658418\n",
      "Epoch: 7 \tTraining Loss: 1.6576 \tValidation Loss: 0.6300\n",
      "BOOM! Validation loss decreased (0.7020 --> 0.6300).  Saving model...\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 1.329011\n",
      "Epoch: 8 \tBatch: 101 \tTraining Loss: 1.594964\n",
      "Epoch: 8 \tBatch: 201 \tTraining Loss: 1.591364\n",
      "Epoch: 8 \tBatch: 301 \tTraining Loss: 1.578150\n",
      "Epoch: 8 \tBatch: 401 \tTraining Loss: 1.581697\n",
      "Epoch: 8 \tBatch: 501 \tTraining Loss: 1.581886\n",
      "Epoch: 8 \tTraining Loss: 1.5896 \tValidation Loss: 0.6160\n",
      "BOOM! Validation loss decreased (0.6300 --> 0.6160).  Saving model...\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 1.232828\n",
      "Epoch: 9 \tBatch: 101 \tTraining Loss: 1.557098\n",
      "Epoch: 9 \tBatch: 201 \tTraining Loss: 1.553038\n",
      "Epoch: 9 \tBatch: 301 \tTraining Loss: 1.551243\n",
      "Epoch: 9 \tBatch: 401 \tTraining Loss: 1.552438\n",
      "Epoch: 9 \tBatch: 501 \tTraining Loss: 1.547465\n",
      "Epoch: 9 \tTraining Loss: 1.5530 \tValidation Loss: 0.5641\n",
      "BOOM! Validation loss decreased (0.6160 --> 0.5641).  Saving model...\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 1.684609\n",
      "Epoch: 10 \tBatch: 101 \tTraining Loss: 1.582847\n",
      "Epoch: 10 \tBatch: 201 \tTraining Loss: 1.553881\n",
      "Epoch: 10 \tBatch: 301 \tTraining Loss: 1.572834\n",
      "Epoch: 10 \tBatch: 401 \tTraining Loss: 1.550233\n",
      "Epoch: 10 \tBatch: 501 \tTraining Loss: 1.547504\n",
      "Epoch: 10 \tTraining Loss: 1.5497 \tValidation Loss: 0.5286\n",
      "BOOM! Validation loss decreased (0.5641 --> 0.5286).  Saving model...\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 1.488981\n",
      "Epoch: 11 \tBatch: 101 \tTraining Loss: 1.504081\n",
      "Epoch: 11 \tBatch: 201 \tTraining Loss: 1.512211\n",
      "Epoch: 11 \tBatch: 301 \tTraining Loss: 1.508037\n",
      "Epoch: 11 \tBatch: 401 \tTraining Loss: 1.501111\n",
      "Epoch: 11 \tBatch: 501 \tTraining Loss: 1.488601\n",
      "Epoch: 11 \tTraining Loss: 1.4947 \tValidation Loss: 0.5188\n",
      "BOOM! Validation loss decreased (0.5286 --> 0.5188).  Saving model...\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 0.962611\n",
      "Epoch: 12 \tBatch: 101 \tTraining Loss: 1.506299\n",
      "Epoch: 12 \tBatch: 201 \tTraining Loss: 1.486850\n",
      "Epoch: 12 \tBatch: 301 \tTraining Loss: 1.498046\n",
      "Epoch: 12 \tBatch: 401 \tTraining Loss: 1.488539\n",
      "Epoch: 12 \tBatch: 501 \tTraining Loss: 1.481339\n",
      "Epoch: 12 \tTraining Loss: 1.4833 \tValidation Loss: 0.4846\n",
      "BOOM! Validation loss decreased (0.5188 --> 0.4846).  Saving model...\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 2.039787\n",
      "Epoch: 13 \tBatch: 101 \tTraining Loss: 1.460161\n",
      "Epoch: 13 \tBatch: 201 \tTraining Loss: 1.474372\n",
      "Epoch: 13 \tBatch: 301 \tTraining Loss: 1.459454\n",
      "Epoch: 13 \tBatch: 401 \tTraining Loss: 1.446585\n",
      "Epoch: 13 \tBatch: 501 \tTraining Loss: 1.447076\n",
      "Epoch: 13 \tTraining Loss: 1.4500 \tValidation Loss: 0.4810\n",
      "BOOM! Validation loss decreased (0.4846 --> 0.4810).  Saving model...\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 1.182785\n",
      "Epoch: 14 \tBatch: 101 \tTraining Loss: 1.436140\n",
      "Epoch: 14 \tBatch: 201 \tTraining Loss: 1.421344\n",
      "Epoch: 14 \tBatch: 301 \tTraining Loss: 1.423788\n",
      "Epoch: 14 \tBatch: 401 \tTraining Loss: 1.431368\n",
      "Epoch: 14 \tBatch: 501 \tTraining Loss: 1.434792\n",
      "Epoch: 14 \tTraining Loss: 1.4336 \tValidation Loss: 0.4874\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 1.302013\n",
      "Epoch: 15 \tBatch: 101 \tTraining Loss: 1.351310\n",
      "Epoch: 15 \tBatch: 201 \tTraining Loss: 1.363010\n",
      "Epoch: 15 \tBatch: 301 \tTraining Loss: 1.395383\n",
      "Epoch: 15 \tBatch: 401 \tTraining Loss: 1.403355\n",
      "Epoch: 15 \tBatch: 501 \tTraining Loss: 1.410016\n",
      "Epoch: 15 \tTraining Loss: 1.4111 \tValidation Loss: 0.4738\n",
      "BOOM! Validation loss decreased (0.4810 --> 0.4738).  Saving model...\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 1.353025\n",
      "Epoch: 16 \tBatch: 101 \tTraining Loss: 1.409921\n",
      "Epoch: 16 \tBatch: 201 \tTraining Loss: 1.394560\n",
      "Epoch: 16 \tBatch: 301 \tTraining Loss: 1.402071\n",
      "Epoch: 16 \tBatch: 401 \tTraining Loss: 1.390654\n",
      "Epoch: 16 \tBatch: 501 \tTraining Loss: 1.407071\n",
      "Epoch: 16 \tTraining Loss: 1.4116 \tValidation Loss: 0.4616\n",
      "BOOM! Validation loss decreased (0.4738 --> 0.4616).  Saving model...\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 1.591300\n",
      "Epoch: 17 \tBatch: 101 \tTraining Loss: 1.398659\n",
      "Epoch: 17 \tBatch: 201 \tTraining Loss: 1.407550\n",
      "Epoch: 17 \tBatch: 301 \tTraining Loss: 1.420730\n",
      "Epoch: 17 \tBatch: 401 \tTraining Loss: 1.416995\n",
      "Epoch: 17 \tBatch: 501 \tTraining Loss: 1.404617\n",
      "Epoch: 17 \tTraining Loss: 1.4068 \tValidation Loss: 0.4436\n",
      "BOOM! Validation loss decreased (0.4616 --> 0.4436).  Saving model...\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 1.816312\n",
      "Epoch: 18 \tBatch: 101 \tTraining Loss: 1.345484\n",
      "Epoch: 18 \tBatch: 201 \tTraining Loss: 1.390950\n",
      "Epoch: 18 \tBatch: 301 \tTraining Loss: 1.384199\n",
      "Epoch: 18 \tBatch: 401 \tTraining Loss: 1.393537\n",
      "Epoch: 18 \tBatch: 501 \tTraining Loss: 1.391968\n",
      "Epoch: 18 \tTraining Loss: 1.3950 \tValidation Loss: 0.4241\n",
      "BOOM! Validation loss decreased (0.4436 --> 0.4241).  Saving model...\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 1.029676\n",
      "Epoch: 19 \tBatch: 101 \tTraining Loss: 1.330604\n",
      "Epoch: 19 \tBatch: 201 \tTraining Loss: 1.376854\n",
      "Epoch: 19 \tBatch: 301 \tTraining Loss: 1.372817\n",
      "Epoch: 19 \tBatch: 401 \tTraining Loss: 1.369632\n",
      "Epoch: 19 \tBatch: 501 \tTraining Loss: 1.378380\n",
      "Epoch: 19 \tTraining Loss: 1.3812 \tValidation Loss: 0.4141\n",
      "BOOM! Validation loss decreased (0.4241 --> 0.4141).  Saving model...\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 1.385862\n",
      "Epoch: 20 \tBatch: 101 \tTraining Loss: 1.355781\n",
      "Epoch: 20 \tBatch: 201 \tTraining Loss: 1.359569\n",
      "Epoch: 20 \tBatch: 301 \tTraining Loss: 1.357650\n",
      "Epoch: 20 \tBatch: 401 \tTraining Loss: 1.351588\n",
      "Epoch: 20 \tBatch: 501 \tTraining Loss: 1.354622\n",
      "Epoch: 20 \tTraining Loss: 1.3611 \tValidation Loss: 0.4226\n",
      "Epoch: 21 \tBatch: 1 \tTraining Loss: 1.660801\n",
      "Epoch: 21 \tBatch: 101 \tTraining Loss: 1.337904\n",
      "Epoch: 21 \tBatch: 201 \tTraining Loss: 1.320150\n",
      "Epoch: 21 \tBatch: 301 \tTraining Loss: 1.352105\n",
      "Epoch: 21 \tBatch: 401 \tTraining Loss: 1.357434\n",
      "Epoch: 21 \tBatch: 501 \tTraining Loss: 1.359985\n",
      "Epoch: 21 \tTraining Loss: 1.3660 \tValidation Loss: 0.4169\n",
      "Epoch: 22 \tBatch: 1 \tTraining Loss: 1.405548\n",
      "Epoch: 22 \tBatch: 101 \tTraining Loss: 1.382758\n",
      "Epoch: 22 \tBatch: 201 \tTraining Loss: 1.396385\n",
      "Epoch: 22 \tBatch: 301 \tTraining Loss: 1.353188\n",
      "Epoch: 22 \tBatch: 401 \tTraining Loss: 1.367004\n",
      "Epoch: 22 \tBatch: 501 \tTraining Loss: 1.362486\n",
      "Epoch: 22 \tTraining Loss: 1.3633 \tValidation Loss: 0.4282\n",
      "Epoch: 23 \tBatch: 1 \tTraining Loss: 1.646476\n",
      "Epoch: 23 \tBatch: 101 \tTraining Loss: 1.369092\n",
      "Epoch: 23 \tBatch: 201 \tTraining Loss: 1.367096\n",
      "Epoch: 23 \tBatch: 301 \tTraining Loss: 1.379756\n",
      "Epoch: 23 \tBatch: 401 \tTraining Loss: 1.373410\n",
      "Epoch: 23 \tBatch: 501 \tTraining Loss: 1.373241\n",
      "Epoch: 23 \tTraining Loss: 1.3759 \tValidation Loss: 0.3921\n",
      "BOOM! Validation loss decreased (0.4141 --> 0.3921).  Saving model...\n",
      "Epoch: 24 \tBatch: 1 \tTraining Loss: 1.338740\n",
      "Epoch: 24 \tBatch: 101 \tTraining Loss: 1.344432\n",
      "Epoch: 24 \tBatch: 201 \tTraining Loss: 1.349757\n",
      "Epoch: 24 \tBatch: 301 \tTraining Loss: 1.341995\n",
      "Epoch: 24 \tBatch: 401 \tTraining Loss: 1.343859\n",
      "Epoch: 24 \tBatch: 501 \tTraining Loss: 1.325656\n",
      "Epoch: 24 \tTraining Loss: 1.3307 \tValidation Loss: 0.3890\n",
      "BOOM! Validation loss decreased (0.3921 --> 0.3890).  Saving model...\n",
      "Epoch: 25 \tBatch: 1 \tTraining Loss: 1.433907\n",
      "Epoch: 25 \tBatch: 101 \tTraining Loss: 1.311425\n",
      "Epoch: 25 \tBatch: 201 \tTraining Loss: 1.328492\n",
      "Epoch: 25 \tBatch: 301 \tTraining Loss: 1.335508\n",
      "Epoch: 25 \tBatch: 401 \tTraining Loss: 1.324829\n",
      "Epoch: 25 \tBatch: 501 \tTraining Loss: 1.317605\n",
      "Epoch: 25 \tTraining Loss: 1.3188 \tValidation Loss: 0.3849\n",
      "BOOM! Validation loss decreased (0.3890 --> 0.3849).  Saving model...\n",
      "Epoch: 26 \tBatch: 1 \tTraining Loss: 1.550880\n",
      "Epoch: 26 \tBatch: 101 \tTraining Loss: 1.286067\n",
      "Epoch: 26 \tBatch: 201 \tTraining Loss: 1.301031\n",
      "Epoch: 26 \tBatch: 301 \tTraining Loss: 1.292315\n",
      "Epoch: 26 \tBatch: 401 \tTraining Loss: 1.310617\n",
      "Epoch: 26 \tBatch: 501 \tTraining Loss: 1.303553\n",
      "Epoch: 26 \tTraining Loss: 1.3054 \tValidation Loss: 0.4069\n",
      "Epoch: 27 \tBatch: 1 \tTraining Loss: 1.176346\n",
      "Epoch: 27 \tBatch: 101 \tTraining Loss: 1.347188\n",
      "Epoch: 27 \tBatch: 201 \tTraining Loss: 1.322094\n",
      "Epoch: 27 \tBatch: 301 \tTraining Loss: 1.315864\n",
      "Epoch: 27 \tBatch: 401 \tTraining Loss: 1.319237\n",
      "Epoch: 27 \tBatch: 501 \tTraining Loss: 1.307868\n",
      "Epoch: 27 \tTraining Loss: 1.3047 \tValidation Loss: 0.3790\n",
      "BOOM! Validation loss decreased (0.3849 --> 0.3790).  Saving model...\n",
      "Epoch: 28 \tBatch: 1 \tTraining Loss: 1.769062\n",
      "Epoch: 28 \tBatch: 101 \tTraining Loss: 1.338965\n",
      "Epoch: 28 \tBatch: 201 \tTraining Loss: 1.318947\n",
      "Epoch: 28 \tBatch: 301 \tTraining Loss: 1.329444\n",
      "Epoch: 28 \tBatch: 401 \tTraining Loss: 1.326933\n",
      "Epoch: 28 \tBatch: 501 \tTraining Loss: 1.314418\n",
      "Epoch: 28 \tTraining Loss: 1.3152 \tValidation Loss: 0.3938\n",
      "Epoch: 29 \tBatch: 1 \tTraining Loss: 1.279526\n",
      "Epoch: 29 \tBatch: 101 \tTraining Loss: 1.285486\n",
      "Epoch: 29 \tBatch: 201 \tTraining Loss: 1.277920\n",
      "Epoch: 29 \tBatch: 301 \tTraining Loss: 1.274345\n",
      "Epoch: 29 \tBatch: 401 \tTraining Loss: 1.279943\n",
      "Epoch: 29 \tBatch: 501 \tTraining Loss: 1.294065\n",
      "Epoch: 29 \tTraining Loss: 1.2975 \tValidation Loss: 0.3788\n",
      "BOOM! Validation loss decreased (0.3790 --> 0.3788).  Saving model...\n",
      "Epoch: 30 \tBatch: 1 \tTraining Loss: 1.924696\n",
      "Epoch: 30 \tBatch: 101 \tTraining Loss: 1.379789\n",
      "Epoch: 30 \tBatch: 201 \tTraining Loss: 1.335876\n",
      "Epoch: 30 \tBatch: 301 \tTraining Loss: 1.330259\n",
      "Epoch: 30 \tBatch: 401 \tTraining Loss: 1.321382\n",
      "Epoch: 30 \tBatch: 501 \tTraining Loss: 1.301592\n",
      "Epoch: 30 \tTraining Loss: 1.3065 \tValidation Loss: 0.3768\n",
      "BOOM! Validation loss decreased (0.3788 --> 0.3768).  Saving model...\n",
      "Epoch: 31 \tBatch: 1 \tTraining Loss: 0.901095\n",
      "Epoch: 31 \tBatch: 101 \tTraining Loss: 1.310862\n",
      "Epoch: 31 \tBatch: 201 \tTraining Loss: 1.288431\n",
      "Epoch: 31 \tBatch: 301 \tTraining Loss: 1.286359\n",
      "Epoch: 31 \tBatch: 401 \tTraining Loss: 1.287832\n",
      "Epoch: 31 \tBatch: 501 \tTraining Loss: 1.290129\n",
      "Epoch: 31 \tTraining Loss: 1.2945 \tValidation Loss: 0.3804\n",
      "Epoch: 32 \tBatch: 1 \tTraining Loss: 1.495337\n",
      "Epoch: 32 \tBatch: 101 \tTraining Loss: 1.255771\n",
      "Epoch: 32 \tBatch: 201 \tTraining Loss: 1.239437\n",
      "Epoch: 32 \tBatch: 301 \tTraining Loss: 1.248174\n",
      "Epoch: 32 \tBatch: 401 \tTraining Loss: 1.260519\n",
      "Epoch: 32 \tBatch: 501 \tTraining Loss: 1.261468\n",
      "Epoch: 32 \tTraining Loss: 1.2720 \tValidation Loss: 0.3762\n",
      "BOOM! Validation loss decreased (0.3768 --> 0.3762).  Saving model...\n",
      "Epoch: 33 \tBatch: 1 \tTraining Loss: 1.593315\n",
      "Epoch: 33 \tBatch: 101 \tTraining Loss: 1.235743\n",
      "Epoch: 33 \tBatch: 201 \tTraining Loss: 1.264749\n",
      "Epoch: 33 \tBatch: 301 \tTraining Loss: 1.276642\n",
      "Epoch: 33 \tBatch: 401 \tTraining Loss: 1.268986\n",
      "Epoch: 33 \tBatch: 501 \tTraining Loss: 1.272441\n",
      "Epoch: 33 \tTraining Loss: 1.2734 \tValidation Loss: 0.3713\n",
      "BOOM! Validation loss decreased (0.3762 --> 0.3713).  Saving model...\n",
      "Epoch: 34 \tBatch: 1 \tTraining Loss: 1.765704\n",
      "Epoch: 34 \tBatch: 101 \tTraining Loss: 1.273715\n",
      "Epoch: 34 \tBatch: 201 \tTraining Loss: 1.296149\n",
      "Epoch: 34 \tBatch: 301 \tTraining Loss: 1.294294\n",
      "Epoch: 34 \tBatch: 401 \tTraining Loss: 1.281787\n",
      "Epoch: 34 \tBatch: 501 \tTraining Loss: 1.281982\n",
      "Epoch: 34 \tTraining Loss: 1.2824 \tValidation Loss: 0.3743\n",
      "Epoch: 35 \tBatch: 1 \tTraining Loss: 1.430408\n",
      "Epoch: 35 \tBatch: 101 \tTraining Loss: 1.255442\n",
      "Epoch: 35 \tBatch: 201 \tTraining Loss: 1.231878\n",
      "Epoch: 35 \tBatch: 301 \tTraining Loss: 1.248157\n",
      "Epoch: 35 \tBatch: 401 \tTraining Loss: 1.252088\n",
      "Epoch: 35 \tBatch: 501 \tTraining Loss: 1.256939\n",
      "Epoch: 35 \tTraining Loss: 1.2665 \tValidation Loss: 0.3548\n",
      "BOOM! Validation loss decreased (0.3713 --> 0.3548).  Saving model...\n",
      "Epoch: 36 \tBatch: 1 \tTraining Loss: 0.841475\n",
      "Epoch: 36 \tBatch: 101 \tTraining Loss: 1.285954\n",
      "Epoch: 36 \tBatch: 201 \tTraining Loss: 1.263866\n",
      "Epoch: 36 \tBatch: 301 \tTraining Loss: 1.265415\n",
      "Epoch: 36 \tBatch: 401 \tTraining Loss: 1.271875\n",
      "Epoch: 36 \tBatch: 501 \tTraining Loss: 1.263413\n",
      "Epoch: 36 \tTraining Loss: 1.2652 \tValidation Loss: 0.3482\n",
      "BOOM! Validation loss decreased (0.3548 --> 0.3482).  Saving model...\n",
      "Epoch: 37 \tBatch: 1 \tTraining Loss: 1.111016\n",
      "Epoch: 37 \tBatch: 101 \tTraining Loss: 1.267565\n",
      "Epoch: 37 \tBatch: 201 \tTraining Loss: 1.282644\n",
      "Epoch: 37 \tBatch: 301 \tTraining Loss: 1.277886\n",
      "Epoch: 37 \tBatch: 401 \tTraining Loss: 1.262882\n",
      "Epoch: 37 \tBatch: 501 \tTraining Loss: 1.259919\n",
      "Epoch: 37 \tTraining Loss: 1.2653 \tValidation Loss: 0.3578\n",
      "Epoch: 38 \tBatch: 1 \tTraining Loss: 0.671769\n",
      "Epoch: 38 \tBatch: 101 \tTraining Loss: 1.256275\n",
      "Epoch: 38 \tBatch: 201 \tTraining Loss: 1.239611\n",
      "Epoch: 38 \tBatch: 301 \tTraining Loss: 1.222353\n",
      "Epoch: 38 \tBatch: 401 \tTraining Loss: 1.237273\n",
      "Epoch: 38 \tBatch: 501 \tTraining Loss: 1.247562\n",
      "Epoch: 38 \tTraining Loss: 1.2502 \tValidation Loss: 0.3510\n",
      "Epoch: 39 \tBatch: 1 \tTraining Loss: 1.771500\n",
      "Epoch: 39 \tBatch: 101 \tTraining Loss: 1.324667\n",
      "Epoch: 39 \tBatch: 201 \tTraining Loss: 1.274267\n",
      "Epoch: 39 \tBatch: 301 \tTraining Loss: 1.265869\n",
      "Epoch: 39 \tBatch: 401 \tTraining Loss: 1.262940\n",
      "Epoch: 39 \tBatch: 501 \tTraining Loss: 1.263587\n",
      "Epoch: 39 \tTraining Loss: 1.2654 \tValidation Loss: 0.3150\n",
      "BOOM! Validation loss decreased (0.3482 --> 0.3150).  Saving model...\n",
      "Epoch: 40 \tBatch: 1 \tTraining Loss: 1.492405\n",
      "Epoch: 40 \tBatch: 101 \tTraining Loss: 1.257298\n",
      "Epoch: 40 \tBatch: 201 \tTraining Loss: 1.250224\n",
      "Epoch: 40 \tBatch: 301 \tTraining Loss: 1.263163\n",
      "Epoch: 40 \tBatch: 401 \tTraining Loss: 1.255196\n",
      "Epoch: 40 \tBatch: 501 \tTraining Loss: 1.256201\n",
      "Epoch: 40 \tTraining Loss: 1.2559 \tValidation Loss: 0.3605\n",
      "Epoch: 41 \tBatch: 1 \tTraining Loss: 0.891649\n",
      "Epoch: 41 \tBatch: 101 \tTraining Loss: 1.196183\n",
      "Epoch: 41 \tBatch: 201 \tTraining Loss: 1.234452\n",
      "Epoch: 41 \tBatch: 301 \tTraining Loss: 1.241654\n",
      "Epoch: 41 \tBatch: 401 \tTraining Loss: 1.248022\n",
      "Epoch: 41 \tBatch: 501 \tTraining Loss: 1.242928\n",
      "Epoch: 41 \tTraining Loss: 1.2453 \tValidation Loss: 0.3347\n",
      "Epoch: 42 \tBatch: 1 \tTraining Loss: 1.628664\n",
      "Epoch: 42 \tBatch: 101 \tTraining Loss: 1.315854\n",
      "Epoch: 42 \tBatch: 201 \tTraining Loss: 1.283709\n",
      "Epoch: 42 \tBatch: 301 \tTraining Loss: 1.274300\n",
      "Epoch: 42 \tBatch: 401 \tTraining Loss: 1.276840\n",
      "Epoch: 42 \tBatch: 501 \tTraining Loss: 1.282272\n",
      "Epoch: 42 \tTraining Loss: 1.2862 \tValidation Loss: 0.3348\n",
      "Epoch: 43 \tBatch: 1 \tTraining Loss: 1.030762\n",
      "Epoch: 43 \tBatch: 101 \tTraining Loss: 1.238990\n",
      "Epoch: 43 \tBatch: 201 \tTraining Loss: 1.208622\n",
      "Epoch: 43 \tBatch: 301 \tTraining Loss: 1.220365\n",
      "Epoch: 43 \tBatch: 401 \tTraining Loss: 1.235516\n",
      "Epoch: 43 \tBatch: 501 \tTraining Loss: 1.230658\n",
      "Epoch: 43 \tTraining Loss: 1.2313 \tValidation Loss: 0.3408\n",
      "Epoch: 44 \tBatch: 1 \tTraining Loss: 1.058295\n",
      "Epoch: 44 \tBatch: 101 \tTraining Loss: 1.257969\n",
      "Epoch: 44 \tBatch: 201 \tTraining Loss: 1.248613\n",
      "Epoch: 44 \tBatch: 301 \tTraining Loss: 1.256518\n",
      "Epoch: 44 \tBatch: 401 \tTraining Loss: 1.251706\n",
      "Epoch: 44 \tBatch: 501 \tTraining Loss: 1.242592\n",
      "Epoch: 44 \tTraining Loss: 1.2472 \tValidation Loss: 0.3304\n",
      "Epoch: 45 \tBatch: 1 \tTraining Loss: 1.065381\n",
      "Epoch: 45 \tBatch: 101 \tTraining Loss: 1.247367\n",
      "Epoch: 45 \tBatch: 201 \tTraining Loss: 1.253512\n",
      "Epoch: 45 \tBatch: 301 \tTraining Loss: 1.231453\n",
      "Epoch: 45 \tBatch: 401 \tTraining Loss: 1.238750\n",
      "Epoch: 45 \tBatch: 501 \tTraining Loss: 1.229970\n",
      "Epoch: 45 \tTraining Loss: 1.2308 \tValidation Loss: 0.3364\n",
      "Epoch: 46 \tBatch: 1 \tTraining Loss: 0.948720\n",
      "Epoch: 46 \tBatch: 101 \tTraining Loss: 1.219089\n",
      "Epoch: 46 \tBatch: 201 \tTraining Loss: 1.239099\n",
      "Epoch: 46 \tBatch: 301 \tTraining Loss: 1.230892\n",
      "Epoch: 46 \tBatch: 401 \tTraining Loss: 1.227453\n",
      "Epoch: 46 \tBatch: 501 \tTraining Loss: 1.239407\n",
      "Epoch: 46 \tTraining Loss: 1.2417 \tValidation Loss: 0.3437\n",
      "Epoch: 47 \tBatch: 1 \tTraining Loss: 1.767639\n",
      "Epoch: 47 \tBatch: 101 \tTraining Loss: 1.241247\n",
      "Epoch: 47 \tBatch: 201 \tTraining Loss: 1.225345\n",
      "Epoch: 47 \tBatch: 301 \tTraining Loss: 1.233051\n",
      "Epoch: 47 \tBatch: 401 \tTraining Loss: 1.230542\n",
      "Epoch: 47 \tBatch: 501 \tTraining Loss: 1.231158\n",
      "Epoch: 47 \tTraining Loss: 1.2336 \tValidation Loss: 0.3529\n",
      "Epoch: 48 \tBatch: 1 \tTraining Loss: 1.151058\n",
      "Epoch: 48 \tBatch: 101 \tTraining Loss: 1.220237\n",
      "Epoch: 48 \tBatch: 201 \tTraining Loss: 1.242196\n",
      "Epoch: 48 \tBatch: 301 \tTraining Loss: 1.228620\n",
      "Epoch: 48 \tBatch: 401 \tTraining Loss: 1.240817\n",
      "Epoch: 48 \tBatch: 501 \tTraining Loss: 1.229797\n",
      "Epoch: 48 \tTraining Loss: 1.2254 \tValidation Loss: 0.3325\n",
      "Epoch: 49 \tBatch: 1 \tTraining Loss: 1.014551\n",
      "Epoch: 49 \tBatch: 101 \tTraining Loss: 1.151665\n",
      "Epoch: 49 \tBatch: 201 \tTraining Loss: 1.194521\n",
      "Epoch: 49 \tBatch: 301 \tTraining Loss: 1.206695\n",
      "Epoch: 49 \tBatch: 401 \tTraining Loss: 1.212178\n",
      "Epoch: 49 \tBatch: 501 \tTraining Loss: 1.223322\n",
      "Epoch: 49 \tTraining Loss: 1.2261 \tValidation Loss: 0.3280\n",
      "Epoch: 50 \tBatch: 1 \tTraining Loss: 1.430127\n",
      "Epoch: 50 \tBatch: 101 \tTraining Loss: 1.250502\n",
      "Epoch: 50 \tBatch: 201 \tTraining Loss: 1.231976\n",
      "Epoch: 50 \tBatch: 301 \tTraining Loss: 1.234437\n",
      "Epoch: 50 \tBatch: 401 \tTraining Loss: 1.238557\n",
      "Epoch: 50 \tBatch: 501 \tTraining Loss: 1.241921\n",
      "Epoch: 50 \tTraining Loss: 1.2444 \tValidation Loss: 0.3327\n",
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 4.778587\n",
      "Epoch: 1 \tBatch: 101 \tTraining Loss: 4.719325\n",
      "Epoch: 1 \tBatch: 201 \tTraining Loss: 4.649905\n",
      "Epoch: 1 \tBatch: 301 \tTraining Loss: 4.583209\n",
      "Epoch: 1 \tBatch: 401 \tTraining Loss: 4.512755\n",
      "Epoch: 1 \tBatch: 501 \tTraining Loss: 4.446927\n",
      "Epoch: 1 \tTraining Loss: 4.4411 \tValidation Loss: 3.7158\n",
      "BOOM! Validation loss decreased (inf --> 3.7158).  Saving model...\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 4.227679\n",
      "Epoch: 2 \tBatch: 101 \tTraining Loss: 4.017863\n",
      "Epoch: 2 \tBatch: 201 \tTraining Loss: 3.974350\n",
      "Epoch: 2 \tBatch: 301 \tTraining Loss: 3.911951\n",
      "Epoch: 2 \tBatch: 401 \tTraining Loss: 3.853544\n",
      "Epoch: 2 \tBatch: 501 \tTraining Loss: 3.796405\n",
      "Epoch: 2 \tTraining Loss: 3.7894 \tValidation Loss: 2.8773\n",
      "BOOM! Validation loss decreased (3.7158 --> 2.8773).  Saving model...\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 3.498784\n",
      "Epoch: 3 \tBatch: 101 \tTraining Loss: 3.444227\n",
      "Epoch: 3 \tBatch: 201 \tTraining Loss: 3.384248\n",
      "Epoch: 3 \tBatch: 301 \tTraining Loss: 3.339445\n",
      "Epoch: 3 \tBatch: 401 \tTraining Loss: 3.303729\n",
      "Epoch: 3 \tBatch: 501 \tTraining Loss: 3.260334\n",
      "Epoch: 3 \tTraining Loss: 3.2576 \tValidation Loss: 2.1774\n",
      "BOOM! Validation loss decreased (2.8773 --> 2.1774).  Saving model...\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 3.520517\n",
      "Epoch: 4 \tBatch: 101 \tTraining Loss: 2.948419\n",
      "Epoch: 4 \tBatch: 201 \tTraining Loss: 2.938022\n",
      "Epoch: 4 \tBatch: 301 \tTraining Loss: 2.938571\n",
      "Epoch: 4 \tBatch: 401 \tTraining Loss: 2.910558\n",
      "Epoch: 4 \tBatch: 501 \tTraining Loss: 2.883792\n",
      "Epoch: 4 \tTraining Loss: 2.8819 \tValidation Loss: 1.7322\n",
      "BOOM! Validation loss decreased (2.1774 --> 1.7322).  Saving model...\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 2.855212\n",
      "Epoch: 5 \tBatch: 101 \tTraining Loss: 2.688667\n",
      "Epoch: 5 \tBatch: 201 \tTraining Loss: 2.677637\n",
      "Epoch: 5 \tBatch: 301 \tTraining Loss: 2.657775\n",
      "Epoch: 5 \tBatch: 401 \tTraining Loss: 2.619165\n",
      "Epoch: 5 \tBatch: 501 \tTraining Loss: 2.596200\n",
      "Epoch: 5 \tTraining Loss: 2.6016 \tValidation Loss: 1.6213\n",
      "BOOM! Validation loss decreased (1.7322 --> 1.6213).  Saving model...\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 2.413463\n",
      "Epoch: 6 \tBatch: 101 \tTraining Loss: 2.467555\n",
      "Epoch: 6 \tBatch: 201 \tTraining Loss: 2.431855\n",
      "Epoch: 6 \tBatch: 301 \tTraining Loss: 2.404020\n",
      "Epoch: 6 \tBatch: 401 \tTraining Loss: 2.393936\n",
      "Epoch: 6 \tBatch: 501 \tTraining Loss: 2.386654\n",
      "Epoch: 6 \tTraining Loss: 2.3939 \tValidation Loss: 1.1707\n",
      "BOOM! Validation loss decreased (1.6213 --> 1.1707).  Saving model...\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 2.173837\n",
      "Epoch: 7 \tBatch: 101 \tTraining Loss: 2.283175\n",
      "Epoch: 7 \tBatch: 201 \tTraining Loss: 2.267957\n",
      "Epoch: 7 \tBatch: 301 \tTraining Loss: 2.252247\n",
      "Epoch: 7 \tBatch: 401 \tTraining Loss: 2.254786\n",
      "Epoch: 7 \tBatch: 501 \tTraining Loss: 2.238312\n",
      "Epoch: 7 \tTraining Loss: 2.2449 \tValidation Loss: 0.9756\n",
      "BOOM! Validation loss decreased (1.1707 --> 0.9756).  Saving model...\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 1.771178\n",
      "Epoch: 8 \tBatch: 101 \tTraining Loss: 2.151136\n",
      "Epoch: 8 \tBatch: 201 \tTraining Loss: 2.124960\n",
      "Epoch: 8 \tBatch: 301 \tTraining Loss: 2.140412\n",
      "Epoch: 8 \tBatch: 401 \tTraining Loss: 2.137787\n",
      "Epoch: 8 \tBatch: 501 \tTraining Loss: 2.130523\n",
      "Epoch: 8 \tTraining Loss: 2.1329 \tValidation Loss: 0.7764\n",
      "BOOM! Validation loss decreased (0.9756 --> 0.7764).  Saving model...\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 2.466428\n",
      "Epoch: 9 \tBatch: 101 \tTraining Loss: 2.023948\n",
      "Epoch: 9 \tBatch: 201 \tTraining Loss: 2.046641\n",
      "Epoch: 9 \tBatch: 301 \tTraining Loss: 2.030718\n",
      "Epoch: 9 \tBatch: 401 \tTraining Loss: 2.025885\n",
      "Epoch: 9 \tBatch: 501 \tTraining Loss: 2.020486\n",
      "Epoch: 9 \tTraining Loss: 2.0224 \tValidation Loss: 0.8689\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 1.866286\n",
      "Epoch: 10 \tBatch: 101 \tTraining Loss: 2.010605\n",
      "Epoch: 10 \tBatch: 201 \tTraining Loss: 1.989674\n",
      "Epoch: 10 \tBatch: 301 \tTraining Loss: 1.964834\n",
      "Epoch: 10 \tBatch: 401 \tTraining Loss: 1.963682\n",
      "Epoch: 10 \tBatch: 501 \tTraining Loss: 1.953167\n",
      "Epoch: 10 \tTraining Loss: 1.9564 \tValidation Loss: 0.8015\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 1.854506\n",
      "Epoch: 11 \tBatch: 101 \tTraining Loss: 1.943054\n",
      "Epoch: 11 \tBatch: 201 \tTraining Loss: 1.934711\n",
      "Epoch: 11 \tBatch: 301 \tTraining Loss: 1.924115\n",
      "Epoch: 11 \tBatch: 401 \tTraining Loss: 1.914030\n",
      "Epoch: 11 \tBatch: 501 \tTraining Loss: 1.914142\n",
      "Epoch: 11 \tTraining Loss: 1.9173 \tValidation Loss: 0.6904\n",
      "BOOM! Validation loss decreased (0.7764 --> 0.6904).  Saving model...\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 1.938486\n",
      "Epoch: 12 \tBatch: 101 \tTraining Loss: 1.837459\n",
      "Epoch: 12 \tBatch: 201 \tTraining Loss: 1.844611\n",
      "Epoch: 12 \tBatch: 301 \tTraining Loss: 1.862548\n",
      "Epoch: 12 \tBatch: 401 \tTraining Loss: 1.857507\n",
      "Epoch: 12 \tBatch: 501 \tTraining Loss: 1.850542\n",
      "Epoch: 12 \tTraining Loss: 1.8526 \tValidation Loss: 0.6213\n",
      "BOOM! Validation loss decreased (0.6904 --> 0.6213).  Saving model...\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 2.248216\n",
      "Epoch: 13 \tBatch: 101 \tTraining Loss: 1.850318\n",
      "Epoch: 13 \tBatch: 201 \tTraining Loss: 1.820347\n",
      "Epoch: 13 \tBatch: 301 \tTraining Loss: 1.805431\n",
      "Epoch: 13 \tBatch: 401 \tTraining Loss: 1.802092\n",
      "Epoch: 13 \tBatch: 501 \tTraining Loss: 1.799190\n",
      "Epoch: 13 \tTraining Loss: 1.8047 \tValidation Loss: 0.7073\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 1.900402\n",
      "Epoch: 14 \tBatch: 101 \tTraining Loss: 1.814312\n",
      "Epoch: 14 \tBatch: 201 \tTraining Loss: 1.757192\n",
      "Epoch: 14 \tBatch: 301 \tTraining Loss: 1.755605\n",
      "Epoch: 14 \tBatch: 401 \tTraining Loss: 1.774212\n",
      "Epoch: 14 \tBatch: 501 \tTraining Loss: 1.761842\n",
      "Epoch: 14 \tTraining Loss: 1.7629 \tValidation Loss: 0.6222\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 1.686913\n",
      "Epoch: 15 \tBatch: 101 \tTraining Loss: 1.792572\n",
      "Epoch: 15 \tBatch: 201 \tTraining Loss: 1.748261\n",
      "Epoch: 15 \tBatch: 301 \tTraining Loss: 1.734443\n",
      "Epoch: 15 \tBatch: 401 \tTraining Loss: 1.741676\n",
      "Epoch: 15 \tBatch: 501 \tTraining Loss: 1.736503\n",
      "Epoch: 15 \tTraining Loss: 1.7405 \tValidation Loss: 0.6099\n",
      "BOOM! Validation loss decreased (0.6213 --> 0.6099).  Saving model...\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 1.106917\n",
      "Epoch: 16 \tBatch: 101 \tTraining Loss: 1.750305\n",
      "Epoch: 16 \tBatch: 201 \tTraining Loss: 1.714890\n",
      "Epoch: 16 \tBatch: 301 \tTraining Loss: 1.699265\n",
      "Epoch: 16 \tBatch: 401 \tTraining Loss: 1.698225\n",
      "Epoch: 16 \tBatch: 501 \tTraining Loss: 1.697045\n",
      "Epoch: 16 \tTraining Loss: 1.7026 \tValidation Loss: 0.5697\n",
      "BOOM! Validation loss decreased (0.6099 --> 0.5697).  Saving model...\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 2.206427\n",
      "Epoch: 17 \tBatch: 101 \tTraining Loss: 1.729912\n",
      "Epoch: 17 \tBatch: 201 \tTraining Loss: 1.706957\n",
      "Epoch: 17 \tBatch: 301 \tTraining Loss: 1.705757\n",
      "Epoch: 17 \tBatch: 401 \tTraining Loss: 1.708415\n",
      "Epoch: 17 \tBatch: 501 \tTraining Loss: 1.707825\n",
      "Epoch: 17 \tTraining Loss: 1.7107 \tValidation Loss: 0.5685\n",
      "BOOM! Validation loss decreased (0.5697 --> 0.5685).  Saving model...\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 1.509391\n",
      "Epoch: 18 \tBatch: 101 \tTraining Loss: 1.708099\n",
      "Epoch: 18 \tBatch: 201 \tTraining Loss: 1.691708\n",
      "Epoch: 18 \tBatch: 301 \tTraining Loss: 1.692758\n",
      "Epoch: 18 \tBatch: 401 \tTraining Loss: 1.684658\n",
      "Epoch: 18 \tBatch: 501 \tTraining Loss: 1.683699\n",
      "Epoch: 18 \tTraining Loss: 1.6894 \tValidation Loss: 0.5751\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 1.534080\n",
      "Epoch: 19 \tBatch: 101 \tTraining Loss: 1.646917\n",
      "Epoch: 19 \tBatch: 201 \tTraining Loss: 1.638338\n",
      "Epoch: 19 \tBatch: 301 \tTraining Loss: 1.637398\n",
      "Epoch: 19 \tBatch: 401 \tTraining Loss: 1.636135\n",
      "Epoch: 19 \tBatch: 501 \tTraining Loss: 1.643928\n",
      "Epoch: 19 \tTraining Loss: 1.6469 \tValidation Loss: 0.5303\n",
      "BOOM! Validation loss decreased (0.5685 --> 0.5303).  Saving model...\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 1.931522\n",
      "Epoch: 20 \tBatch: 101 \tTraining Loss: 1.609935\n",
      "Epoch: 20 \tBatch: 201 \tTraining Loss: 1.628639\n",
      "Epoch: 20 \tBatch: 301 \tTraining Loss: 1.617828\n",
      "Epoch: 20 \tBatch: 401 \tTraining Loss: 1.611364\n",
      "Epoch: 20 \tBatch: 501 \tTraining Loss: 1.611709\n",
      "Epoch: 20 \tTraining Loss: 1.6175 \tValidation Loss: 0.5619\n",
      "Epoch: 21 \tBatch: 1 \tTraining Loss: 1.490957\n",
      "Epoch: 21 \tBatch: 101 \tTraining Loss: 1.598574\n",
      "Epoch: 21 \tBatch: 201 \tTraining Loss: 1.623410\n",
      "Epoch: 21 \tBatch: 301 \tTraining Loss: 1.630728\n",
      "Epoch: 21 \tBatch: 401 \tTraining Loss: 1.641319\n",
      "Epoch: 21 \tBatch: 501 \tTraining Loss: 1.638246\n",
      "Epoch: 21 \tTraining Loss: 1.6431 \tValidation Loss: 0.5283\n",
      "BOOM! Validation loss decreased (0.5303 --> 0.5283).  Saving model...\n",
      "Epoch: 22 \tBatch: 1 \tTraining Loss: 1.105075\n",
      "Epoch: 22 \tBatch: 101 \tTraining Loss: 1.610685\n",
      "Epoch: 22 \tBatch: 201 \tTraining Loss: 1.602832\n",
      "Epoch: 22 \tBatch: 301 \tTraining Loss: 1.614188\n",
      "Epoch: 22 \tBatch: 401 \tTraining Loss: 1.618460\n",
      "Epoch: 22 \tBatch: 501 \tTraining Loss: 1.615993\n",
      "Epoch: 22 \tTraining Loss: 1.6211 \tValidation Loss: 0.4844\n",
      "BOOM! Validation loss decreased (0.5283 --> 0.4844).  Saving model...\n",
      "Epoch: 23 \tBatch: 1 \tTraining Loss: 1.881637\n",
      "Epoch: 23 \tBatch: 101 \tTraining Loss: 1.582657\n",
      "Epoch: 23 \tBatch: 201 \tTraining Loss: 1.596146\n",
      "Epoch: 23 \tBatch: 301 \tTraining Loss: 1.600964\n",
      "Epoch: 23 \tBatch: 401 \tTraining Loss: 1.574875\n",
      "Epoch: 23 \tBatch: 501 \tTraining Loss: 1.581903\n",
      "Epoch: 23 \tTraining Loss: 1.5874 \tValidation Loss: 0.5113\n",
      "Epoch: 24 \tBatch: 1 \tTraining Loss: 1.198735\n",
      "Epoch: 24 \tBatch: 101 \tTraining Loss: 1.566267\n",
      "Epoch: 24 \tBatch: 201 \tTraining Loss: 1.557271\n",
      "Epoch: 24 \tBatch: 301 \tTraining Loss: 1.561630\n",
      "Epoch: 24 \tBatch: 401 \tTraining Loss: 1.580158\n",
      "Epoch: 24 \tBatch: 501 \tTraining Loss: 1.571880\n",
      "Epoch: 24 \tTraining Loss: 1.5787 \tValidation Loss: 0.5299\n",
      "Epoch: 25 \tBatch: 1 \tTraining Loss: 1.299983\n",
      "Epoch: 25 \tBatch: 101 \tTraining Loss: 1.540614\n",
      "Epoch: 25 \tBatch: 201 \tTraining Loss: 1.546332\n",
      "Epoch: 25 \tBatch: 301 \tTraining Loss: 1.553474\n",
      "Epoch: 25 \tBatch: 401 \tTraining Loss: 1.556906\n",
      "Epoch: 25 \tBatch: 501 \tTraining Loss: 1.552659\n",
      "Epoch: 25 \tTraining Loss: 1.5535 \tValidation Loss: 0.5359\n",
      "Epoch: 26 \tBatch: 1 \tTraining Loss: 1.693537\n",
      "Epoch: 26 \tBatch: 101 \tTraining Loss: 1.601844\n",
      "Epoch: 26 \tBatch: 201 \tTraining Loss: 1.570254\n",
      "Epoch: 26 \tBatch: 301 \tTraining Loss: 1.563157\n",
      "Epoch: 26 \tBatch: 401 \tTraining Loss: 1.558148\n",
      "Epoch: 26 \tBatch: 501 \tTraining Loss: 1.555555\n",
      "Epoch: 26 \tTraining Loss: 1.5557 \tValidation Loss: 0.4711\n",
      "BOOM! Validation loss decreased (0.4844 --> 0.4711).  Saving model...\n",
      "Epoch: 27 \tBatch: 1 \tTraining Loss: 1.349703\n",
      "Epoch: 27 \tBatch: 101 \tTraining Loss: 1.534821\n",
      "Epoch: 27 \tBatch: 201 \tTraining Loss: 1.533746\n",
      "Epoch: 27 \tBatch: 301 \tTraining Loss: 1.517465\n",
      "Epoch: 27 \tBatch: 401 \tTraining Loss: 1.518178\n",
      "Epoch: 27 \tBatch: 501 \tTraining Loss: 1.526431\n",
      "Epoch: 27 \tTraining Loss: 1.5259 \tValidation Loss: 0.4735\n",
      "Epoch: 28 \tBatch: 1 \tTraining Loss: 1.986525\n",
      "Epoch: 28 \tBatch: 101 \tTraining Loss: 1.536722\n",
      "Epoch: 28 \tBatch: 201 \tTraining Loss: 1.532386\n",
      "Epoch: 28 \tBatch: 301 \tTraining Loss: 1.519528\n",
      "Epoch: 28 \tBatch: 401 \tTraining Loss: 1.520158\n",
      "Epoch: 28 \tBatch: 501 \tTraining Loss: 1.523933\n",
      "Epoch: 28 \tTraining Loss: 1.5274 \tValidation Loss: 0.4996\n",
      "Epoch: 29 \tBatch: 1 \tTraining Loss: 1.384415\n",
      "Epoch: 29 \tBatch: 101 \tTraining Loss: 1.584602\n",
      "Epoch: 29 \tBatch: 201 \tTraining Loss: 1.574260\n",
      "Epoch: 29 \tBatch: 301 \tTraining Loss: 1.558857\n",
      "Epoch: 29 \tBatch: 401 \tTraining Loss: 1.547927\n",
      "Epoch: 29 \tBatch: 501 \tTraining Loss: 1.541305\n",
      "Epoch: 29 \tTraining Loss: 1.5459 \tValidation Loss: 0.4599\n",
      "BOOM! Validation loss decreased (0.4711 --> 0.4599).  Saving model...\n",
      "Epoch: 30 \tBatch: 1 \tTraining Loss: 1.627319\n",
      "Epoch: 30 \tBatch: 101 \tTraining Loss: 1.565102\n",
      "Epoch: 30 \tBatch: 201 \tTraining Loss: 1.559792\n",
      "Epoch: 30 \tBatch: 301 \tTraining Loss: 1.545678\n",
      "Epoch: 30 \tBatch: 401 \tTraining Loss: 1.536125\n",
      "Epoch: 30 \tBatch: 501 \tTraining Loss: 1.535605\n",
      "Epoch: 30 \tTraining Loss: 1.5374 \tValidation Loss: 0.4511\n",
      "BOOM! Validation loss decreased (0.4599 --> 0.4511).  Saving model...\n",
      "Epoch: 31 \tBatch: 1 \tTraining Loss: 1.842960\n",
      "Epoch: 31 \tBatch: 101 \tTraining Loss: 1.540730\n",
      "Epoch: 31 \tBatch: 201 \tTraining Loss: 1.511855\n",
      "Epoch: 31 \tBatch: 301 \tTraining Loss: 1.529536\n",
      "Epoch: 31 \tBatch: 401 \tTraining Loss: 1.518374\n",
      "Epoch: 31 \tBatch: 501 \tTraining Loss: 1.529358\n",
      "Epoch: 31 \tTraining Loss: 1.5367 \tValidation Loss: 0.4529\n",
      "Epoch: 32 \tBatch: 1 \tTraining Loss: 1.898178\n",
      "Epoch: 32 \tBatch: 101 \tTraining Loss: 1.512219\n",
      "Epoch: 32 \tBatch: 201 \tTraining Loss: 1.509094\n",
      "Epoch: 32 \tBatch: 301 \tTraining Loss: 1.513665\n",
      "Epoch: 32 \tBatch: 401 \tTraining Loss: 1.511108\n",
      "Epoch: 32 \tBatch: 501 \tTraining Loss: 1.515401\n",
      "Epoch: 32 \tTraining Loss: 1.5198 \tValidation Loss: 0.4323\n",
      "BOOM! Validation loss decreased (0.4511 --> 0.4323).  Saving model...\n",
      "Epoch: 33 \tBatch: 1 \tTraining Loss: 1.424034\n",
      "Epoch: 33 \tBatch: 101 \tTraining Loss: 1.521247\n",
      "Epoch: 33 \tBatch: 201 \tTraining Loss: 1.477655\n",
      "Epoch: 33 \tBatch: 301 \tTraining Loss: 1.495554\n",
      "Epoch: 33 \tBatch: 401 \tTraining Loss: 1.490997\n",
      "Epoch: 33 \tBatch: 501 \tTraining Loss: 1.475188\n",
      "Epoch: 33 \tTraining Loss: 1.4810 \tValidation Loss: 0.4942\n",
      "Epoch: 34 \tBatch: 1 \tTraining Loss: 1.077576\n",
      "Epoch: 34 \tBatch: 101 \tTraining Loss: 1.475130\n",
      "Epoch: 34 \tBatch: 201 \tTraining Loss: 1.474907\n",
      "Epoch: 34 \tBatch: 301 \tTraining Loss: 1.486079\n",
      "Epoch: 34 \tBatch: 401 \tTraining Loss: 1.493229\n",
      "Epoch: 34 \tBatch: 501 \tTraining Loss: 1.492855\n",
      "Epoch: 34 \tTraining Loss: 1.4999 \tValidation Loss: 0.4646\n",
      "Epoch: 35 \tBatch: 1 \tTraining Loss: 1.427761\n",
      "Epoch: 35 \tBatch: 101 \tTraining Loss: 1.447497\n",
      "Epoch: 35 \tBatch: 201 \tTraining Loss: 1.469964\n",
      "Epoch: 35 \tBatch: 301 \tTraining Loss: 1.471022\n",
      "Epoch: 35 \tBatch: 401 \tTraining Loss: 1.462689\n",
      "Epoch: 35 \tBatch: 501 \tTraining Loss: 1.467795\n",
      "Epoch: 35 \tTraining Loss: 1.4745 \tValidation Loss: 0.4643\n",
      "Epoch: 36 \tBatch: 1 \tTraining Loss: 1.659105\n",
      "Epoch: 36 \tBatch: 101 \tTraining Loss: 1.457043\n",
      "Epoch: 36 \tBatch: 201 \tTraining Loss: 1.455273\n",
      "Epoch: 36 \tBatch: 301 \tTraining Loss: 1.453838\n",
      "Epoch: 36 \tBatch: 401 \tTraining Loss: 1.460097\n",
      "Epoch: 36 \tBatch: 501 \tTraining Loss: 1.463586\n",
      "Epoch: 36 \tTraining Loss: 1.4708 \tValidation Loss: 0.4467\n",
      "Epoch: 37 \tBatch: 1 \tTraining Loss: 1.697340\n",
      "Epoch: 37 \tBatch: 101 \tTraining Loss: 1.447754\n",
      "Epoch: 37 \tBatch: 201 \tTraining Loss: 1.443214\n",
      "Epoch: 37 \tBatch: 301 \tTraining Loss: 1.447775\n",
      "Epoch: 37 \tBatch: 401 \tTraining Loss: 1.448261\n",
      "Epoch: 37 \tBatch: 501 \tTraining Loss: 1.465500\n",
      "Epoch: 37 \tTraining Loss: 1.4685 \tValidation Loss: 0.4687\n",
      "Epoch: 38 \tBatch: 1 \tTraining Loss: 1.481130\n",
      "Epoch: 38 \tBatch: 101 \tTraining Loss: 1.470829\n",
      "Epoch: 38 \tBatch: 201 \tTraining Loss: 1.478911\n",
      "Epoch: 38 \tBatch: 301 \tTraining Loss: 1.494049\n",
      "Epoch: 38 \tBatch: 401 \tTraining Loss: 1.492005\n",
      "Epoch: 38 \tBatch: 501 \tTraining Loss: 1.493639\n",
      "Epoch: 38 \tTraining Loss: 1.4971 \tValidation Loss: 0.4567\n",
      "Epoch: 39 \tBatch: 1 \tTraining Loss: 1.210646\n",
      "Epoch: 39 \tBatch: 101 \tTraining Loss: 1.468816\n",
      "Epoch: 39 \tBatch: 201 \tTraining Loss: 1.443854\n",
      "Epoch: 39 \tBatch: 301 \tTraining Loss: 1.442814\n",
      "Epoch: 39 \tBatch: 401 \tTraining Loss: 1.452421\n",
      "Epoch: 39 \tBatch: 501 \tTraining Loss: 1.448201\n",
      "Epoch: 39 \tTraining Loss: 1.4528 \tValidation Loss: 0.4596\n",
      "Epoch: 40 \tBatch: 1 \tTraining Loss: 1.108305\n",
      "Epoch: 40 \tBatch: 101 \tTraining Loss: 1.398532\n",
      "Epoch: 40 \tBatch: 201 \tTraining Loss: 1.392257\n",
      "Epoch: 40 \tBatch: 301 \tTraining Loss: 1.392672\n",
      "Epoch: 40 \tBatch: 401 \tTraining Loss: 1.402583\n",
      "Epoch: 40 \tBatch: 501 \tTraining Loss: 1.415424\n",
      "Epoch: 40 \tTraining Loss: 1.4169 \tValidation Loss: 0.4201\n",
      "BOOM! Validation loss decreased (0.4323 --> 0.4201).  Saving model...\n",
      "Epoch: 41 \tBatch: 1 \tTraining Loss: 1.817411\n",
      "Epoch: 41 \tBatch: 101 \tTraining Loss: 1.425014\n",
      "Epoch: 41 \tBatch: 201 \tTraining Loss: 1.422666\n",
      "Epoch: 41 \tBatch: 301 \tTraining Loss: 1.416773\n",
      "Epoch: 41 \tBatch: 401 \tTraining Loss: 1.423113\n",
      "Epoch: 41 \tBatch: 501 \tTraining Loss: 1.429464\n",
      "Epoch: 41 \tTraining Loss: 1.4341 \tValidation Loss: 0.4537\n",
      "Epoch: 42 \tBatch: 1 \tTraining Loss: 1.543890\n",
      "Epoch: 42 \tBatch: 101 \tTraining Loss: 1.436637\n",
      "Epoch: 42 \tBatch: 201 \tTraining Loss: 1.445566\n",
      "Epoch: 42 \tBatch: 301 \tTraining Loss: 1.446517\n",
      "Epoch: 42 \tBatch: 401 \tTraining Loss: 1.441417\n",
      "Epoch: 42 \tBatch: 501 \tTraining Loss: 1.426614\n",
      "Epoch: 42 \tTraining Loss: 1.4254 \tValidation Loss: 0.4141\n",
      "BOOM! Validation loss decreased (0.4201 --> 0.4141).  Saving model...\n",
      "Epoch: 43 \tBatch: 1 \tTraining Loss: 2.137295\n",
      "Epoch: 43 \tBatch: 101 \tTraining Loss: 1.431663\n",
      "Epoch: 43 \tBatch: 201 \tTraining Loss: 1.422331\n",
      "Epoch: 43 \tBatch: 301 \tTraining Loss: 1.435854\n",
      "Epoch: 43 \tBatch: 401 \tTraining Loss: 1.439998\n",
      "Epoch: 43 \tBatch: 501 \tTraining Loss: 1.441768\n",
      "Epoch: 43 \tTraining Loss: 1.4448 \tValidation Loss: 0.4364\n",
      "Epoch: 44 \tBatch: 1 \tTraining Loss: 1.637016\n",
      "Epoch: 44 \tBatch: 101 \tTraining Loss: 1.380386\n",
      "Epoch: 44 \tBatch: 201 \tTraining Loss: 1.374041\n",
      "Epoch: 44 \tBatch: 301 \tTraining Loss: 1.390297\n",
      "Epoch: 44 \tBatch: 401 \tTraining Loss: 1.385152\n",
      "Epoch: 44 \tBatch: 501 \tTraining Loss: 1.394988\n",
      "Epoch: 44 \tTraining Loss: 1.3990 \tValidation Loss: 0.4419\n",
      "Epoch: 45 \tBatch: 1 \tTraining Loss: 0.776210\n",
      "Epoch: 45 \tBatch: 101 \tTraining Loss: 1.454239\n",
      "Epoch: 45 \tBatch: 201 \tTraining Loss: 1.417695\n",
      "Epoch: 45 \tBatch: 301 \tTraining Loss: 1.416089\n",
      "Epoch: 45 \tBatch: 401 \tTraining Loss: 1.423357\n",
      "Epoch: 45 \tBatch: 501 \tTraining Loss: 1.422795\n",
      "Epoch: 45 \tTraining Loss: 1.4236 \tValidation Loss: 0.4469\n",
      "Epoch: 46 \tBatch: 1 \tTraining Loss: 0.818126\n",
      "Epoch: 46 \tBatch: 101 \tTraining Loss: 1.411479\n",
      "Epoch: 46 \tBatch: 201 \tTraining Loss: 1.429539\n",
      "Epoch: 46 \tBatch: 301 \tTraining Loss: 1.441498\n",
      "Epoch: 46 \tBatch: 401 \tTraining Loss: 1.437147\n",
      "Epoch: 46 \tBatch: 501 \tTraining Loss: 1.433497\n",
      "Epoch: 46 \tTraining Loss: 1.4361 \tValidation Loss: 0.4444\n",
      "Epoch: 47 \tBatch: 1 \tTraining Loss: 1.751288\n",
      "Epoch: 47 \tBatch: 101 \tTraining Loss: 1.433854\n",
      "Epoch: 47 \tBatch: 201 \tTraining Loss: 1.405245\n",
      "Epoch: 47 \tBatch: 301 \tTraining Loss: 1.392585\n",
      "Epoch: 47 \tBatch: 401 \tTraining Loss: 1.403255\n",
      "Epoch: 47 \tBatch: 501 \tTraining Loss: 1.409929\n",
      "Epoch: 47 \tTraining Loss: 1.4179 \tValidation Loss: 0.4297\n",
      "Epoch: 48 \tBatch: 1 \tTraining Loss: 1.336768\n",
      "Epoch: 48 \tBatch: 101 \tTraining Loss: 1.415406\n",
      "Epoch: 48 \tBatch: 201 \tTraining Loss: 1.435710\n",
      "Epoch: 48 \tBatch: 301 \tTraining Loss: 1.426667\n",
      "Epoch: 48 \tBatch: 401 \tTraining Loss: 1.416952\n",
      "Epoch: 48 \tBatch: 501 \tTraining Loss: 1.420063\n",
      "Epoch: 48 \tTraining Loss: 1.4216 \tValidation Loss: 0.4403\n",
      "Epoch: 49 \tBatch: 1 \tTraining Loss: 1.338297\n",
      "Epoch: 49 \tBatch: 101 \tTraining Loss: 1.424578\n",
      "Epoch: 49 \tBatch: 201 \tTraining Loss: 1.402923\n",
      "Epoch: 49 \tBatch: 301 \tTraining Loss: 1.406291\n",
      "Epoch: 49 \tBatch: 401 \tTraining Loss: 1.400942\n",
      "Epoch: 49 \tBatch: 501 \tTraining Loss: 1.401086\n",
      "Epoch: 49 \tTraining Loss: 1.4063 \tValidation Loss: 0.4259\n",
      "Epoch: 50 \tBatch: 1 \tTraining Loss: 1.488702\n",
      "Epoch: 50 \tBatch: 101 \tTraining Loss: 1.360758\n",
      "Epoch: 50 \tBatch: 201 \tTraining Loss: 1.383103\n",
      "Epoch: 50 \tBatch: 301 \tTraining Loss: 1.400415\n",
      "Epoch: 50 \tBatch: 401 \tTraining Loss: 1.405063\n",
      "Epoch: 50 \tBatch: 501 \tTraining Loss: 1.403783\n",
      "Epoch: 50 \tTraining Loss: 1.4079 \tValidation Loss: 0.4139\n",
      "BOOM! Validation loss decreased (0.4141 --> 0.4139).  Saving model...\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "model_resnet =  train(n_epochs, dataloaders, model_resnet, optimizer_resnet, criterion_resnet, use_cuda, 'model_resnet.pt')\n",
    "model_xception =  train(n_epochs, dataloaders, model_xception, optimizer_xception, criterion_xception, use_cuda, 'model_xception.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6c190e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:18:47.602420Z",
     "iopub.status.busy": "2025-09-21T02:18:47.602141Z",
     "iopub.status.idle": "2025-09-21T02:18:47.870503Z",
     "shell.execute_reply": "2025-09-21T02:18:47.869718Z"
    },
    "papermill": {
     "duration": 0.301264,
     "end_time": "2025-09-21T02:18:47.871902",
     "exception": false,
     "start_time": "2025-09-21T02:18:47.570638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(sample)\n",
    "ids = sample_sub[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58d2da5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:18:47.935776Z",
     "iopub.status.busy": "2025-09-21T02:18:47.935552Z",
     "iopub.status.idle": "2025-09-21T02:23:01.261967Z",
     "shell.execute_reply": "2025-09-21T02:23:01.261186Z"
    },
    "papermill": {
     "duration": 253.359219,
     "end_time": "2025-09-21T02:23:01.263368",
     "exception": false,
     "start_time": "2025-09-21T02:18:47.904149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "model_resnet.eval()\n",
    "model_xception.eval()\n",
    "\n",
    "for uid in ids:\n",
    "    img_path = testroot + '/' + uid + '.jpg'\n",
    "    img = Image.open(img_path)\n",
    "    img = img_transform['test'](img)\n",
    "    img = img.unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        out = model_resnet(img)\n",
    "        out2 = model_xception(img)\n",
    "    \n",
    "    out = out.view(-1)\n",
    "    out2 = out2.view(-1)\n",
    "    out = torch.softmax(out, dim = 0)\n",
    "    out2 = torch.softmax(out2, dim = 0)\n",
    "    avg = (out + out2) / 2\n",
    "    prediction.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc9d715d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:01.327551Z",
     "iopub.status.busy": "2025-09-21T02:23:01.327319Z",
     "iopub.status.idle": "2025-09-21T02:23:01.408616Z",
     "shell.execute_reply": "2025-09-21T02:23:01.407862Z"
    },
    "papermill": {
     "duration": 0.113832,
     "end_time": "2025-09-21T02:23:01.409791",
     "exception": false,
     "start_time": "2025-09-21T02:23:01.295959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.7837e-07, 3.3371e-06, 1.7735e-07, 1.6235e-07, 5.1930e-08, 2.8693e-07,\n",
      "        1.1859e-07, 1.5180e-07, 1.5272e-07, 4.4851e-07, 9.2909e-08, 1.9589e-06,\n",
      "        3.5342e-07, 6.8743e-04, 1.6465e-07, 4.5137e-07, 1.0123e-06, 4.4958e-08,\n",
      "        2.4580e-06, 3.6612e-06, 1.3580e-07, 8.3934e-07, 1.4134e-05, 1.6506e-07,\n",
      "        7.3553e-06, 1.1689e-07, 8.8144e-08, 1.2192e-07, 1.5238e-07, 2.3569e-06,\n",
      "        4.0852e-07, 2.0610e-06, 1.1903e-06, 1.2577e-06, 1.1899e-07, 5.9255e-08,\n",
      "        3.4688e-07, 8.2416e-08, 1.4930e-07, 1.6363e-07, 8.5405e-07, 1.2273e-06,\n",
      "        5.7050e-07, 1.2056e-07, 2.1426e-07, 6.9117e-07, 3.2904e-08, 2.7815e-07,\n",
      "        8.2899e-08, 3.2971e-07, 3.0321e-07, 2.7778e-07, 2.3298e-06, 2.8824e-07,\n",
      "        6.9755e-08, 1.2984e-07, 3.5818e-07, 7.3712e-08, 1.7274e-07, 4.3432e-08,\n",
      "        1.2502e-07, 9.7666e-01, 3.9428e-07, 9.4870e-08, 3.5448e-07, 1.4550e-07,\n",
      "        1.3153e-07, 7.9408e-08, 2.6143e-08, 2.2895e-07, 5.3785e-05, 1.1422e-07,\n",
      "        4.1125e-08, 6.4368e-06, 1.1892e-07, 1.5691e-07, 2.4502e-07, 6.1418e-08,\n",
      "        6.9454e-07, 1.0927e-07, 3.7277e-08, 3.5692e-08, 5.1120e-07, 1.2056e-07,\n",
      "        6.5328e-04, 2.1462e-02, 9.4191e-08, 1.0674e-05, 1.4176e-06, 3.1874e-07,\n",
      "        3.3238e-07, 1.1092e-07, 2.8867e-06, 1.5925e-06, 3.8086e-07, 1.6166e-07,\n",
      "        3.8888e-08, 7.7517e-08, 1.7183e-07, 2.4966e-05, 3.6462e-04, 1.4008e-07,\n",
      "        5.9213e-07, 4.9814e-08, 1.1574e-07, 1.8612e-07, 5.0235e-08, 6.0837e-07,\n",
      "        3.1345e-07, 8.1501e-06, 3.0583e-07, 6.1498e-07, 2.0526e-07, 1.8455e-07,\n",
      "        2.0130e-07, 3.9224e-07, 1.0051e-07, 2.2078e-07, 1.6748e-07, 6.0182e-07],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "776659ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:01.473603Z",
     "iopub.status.busy": "2025-09-21T02:23:01.473369Z",
     "iopub.status.idle": "2025-09-21T02:23:01.493151Z",
     "shell.execute_reply": "2025-09-21T02:23:01.492468Z"
    },
    "papermill": {
     "duration": 0.052279,
     "end_time": "2025-09-21T02:23:01.494216",
     "exception": false,
     "start_time": "2025-09-21T02:23:01.441937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  000621fb3cbb32d8935728e48679680e       0.008333      0.008333   \n",
       "1  00102ee9d8eb90812350685311fe5890       0.008333      0.008333   \n",
       "2  0012a730dfa437f5f3613fb75efcd4ce       0.008333      0.008333   \n",
       "3  001510bc8570bbeee98c8d80c8a95ec1       0.008333      0.008333   \n",
       "4  001a5f3114548acdefa3d4da05474c2e       0.008333      0.008333   \n",
       "\n",
       "   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n",
       "0             0.008333  0.008333                        0.008333     0.008333   \n",
       "1             0.008333  0.008333                        0.008333     0.008333   \n",
       "2             0.008333  0.008333                        0.008333     0.008333   \n",
       "3             0.008333  0.008333                        0.008333     0.008333   \n",
       "4             0.008333  0.008333                        0.008333     0.008333   \n",
       "\n",
       "   australian_terrier   basenji    basset  ...  toy_poodle  toy_terrier  \\\n",
       "0            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "1            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "2            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "3            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "4            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "\n",
       "     vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0  0.008333      0.008333    0.008333                0.008333   \n",
       "1  0.008333      0.008333    0.008333                0.008333   \n",
       "2  0.008333      0.008333    0.008333                0.008333   \n",
       "3  0.008333      0.008333    0.008333                0.008333   \n",
       "4  0.008333      0.008333    0.008333                0.008333   \n",
       "\n",
       "   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n",
       "0                     0.008333  0.008333                 0.008333   \n",
       "1                     0.008333  0.008333                 0.008333   \n",
       "2                     0.008333  0.008333                 0.008333   \n",
       "3                     0.008333  0.008333                 0.008333   \n",
       "4                     0.008333  0.008333                 0.008333   \n",
       "\n",
       "   yorkshire_terrier  \n",
       "0           0.008333  \n",
       "1           0.008333  \n",
       "2           0.008333  \n",
       "3           0.008333  \n",
       "4           0.008333  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd2bea50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:01.557232Z",
     "iopub.status.busy": "2025-09-21T02:23:01.556922Z",
     "iopub.status.idle": "2025-09-21T02:23:01.565941Z",
     "shell.execute_reply": "2025-09-21T02:23:01.565216Z"
    },
    "papermill": {
     "duration": 0.041805,
     "end_time": "2025-09-21T02:23:01.567121",
     "exception": false,
     "start_time": "2025-09-21T02:23:01.525316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_sub = sample_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "593fa623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:01.632987Z",
     "iopub.status.busy": "2025-09-21T02:23:01.632750Z",
     "iopub.status.idle": "2025-09-21T02:23:01.858279Z",
     "shell.execute_reply": "2025-09-21T02:23:01.857486Z"
    },
    "papermill": {
     "duration": 0.261342,
     "end_time": "2025-09-21T02:23:01.859764",
     "exception": false,
     "start_time": "2025-09-21T02:23:01.598422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = [p.detach().cpu().numpy() for p in prediction]\n",
    "prediction = np.vstack(prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3487fb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:01.924200Z",
     "iopub.status.busy": "2025-09-21T02:23:01.923953Z",
     "iopub.status.idle": "2025-09-21T02:23:01.932493Z",
     "shell.execute_reply": "2025-09-21T02:23:01.931999Z"
    },
    "papermill": {
     "duration": 0.041708,
     "end_time": "2025-09-21T02:23:01.933610",
     "exception": false,
     "start_time": "2025-09-21T02:23:01.891902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_sub.iloc[:, 1:] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a0acd8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:01.999617Z",
     "iopub.status.busy": "2025-09-21T02:23:01.999394Z",
     "iopub.status.idle": "2025-09-21T02:23:02.017519Z",
     "shell.execute_reply": "2025-09-21T02:23:02.016973Z"
    },
    "papermill": {
     "duration": 0.051406,
     "end_time": "2025-09-21T02:23:02.018510",
     "exception": false,
     "start_time": "2025-09-21T02:23:01.967104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>9.783715e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.773483e-07</td>\n",
       "      <td>1.623504e-07</td>\n",
       "      <td>5.192971e-08</td>\n",
       "      <td>2.869335e-07</td>\n",
       "      <td>1.185932e-07</td>\n",
       "      <td>1.517987e-07</td>\n",
       "      <td>1.527176e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.058285e-07</td>\n",
       "      <td>6.149770e-07</td>\n",
       "      <td>2.052570e-07</td>\n",
       "      <td>1.845535e-07</td>\n",
       "      <td>2.013001e-07</td>\n",
       "      <td>3.922409e-07</td>\n",
       "      <td>1.005067e-07</td>\n",
       "      <td>2.207841e-07</td>\n",
       "      <td>1.674841e-07</td>\n",
       "      <td>6.018194e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>3.904235e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.349749e-06</td>\n",
       "      <td>3.222111e-06</td>\n",
       "      <td>2.799774e-06</td>\n",
       "      <td>3.205525e-06</td>\n",
       "      <td>2.429732e-06</td>\n",
       "      <td>2.776531e-06</td>\n",
       "      <td>1.035491e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178894e-05</td>\n",
       "      <td>9.557832e-07</td>\n",
       "      <td>2.354040e-06</td>\n",
       "      <td>1.257419e-06</td>\n",
       "      <td>1.265381e-06</td>\n",
       "      <td>8.060605e-07</td>\n",
       "      <td>5.633652e-05</td>\n",
       "      <td>1.393395e-06</td>\n",
       "      <td>8.355050e-07</td>\n",
       "      <td>2.548201e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>1.803103e-06</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>2.591239e-06</td>\n",
       "      <td>6.032020e-06</td>\n",
       "      <td>2.033924e-06</td>\n",
       "      <td>2.935269e-05</td>\n",
       "      <td>2.417689e-06</td>\n",
       "      <td>2.832639e-07</td>\n",
       "      <td>5.678557e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.179981e-07</td>\n",
       "      <td>4.658894e-06</td>\n",
       "      <td>4.792734e-06</td>\n",
       "      <td>1.388795e-04</td>\n",
       "      <td>6.675890e-05</td>\n",
       "      <td>8.983470e-03</td>\n",
       "      <td>3.536553e-06</td>\n",
       "      <td>2.779912e-06</td>\n",
       "      <td>3.517055e-06</td>\n",
       "      <td>1.412737e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>3.248847e-03</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.016343e-05</td>\n",
       "      <td>1.129691e-05</td>\n",
       "      <td>1.574612e-03</td>\n",
       "      <td>2.237491e-04</td>\n",
       "      <td>3.482581e-06</td>\n",
       "      <td>8.029431e-05</td>\n",
       "      <td>5.339699e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736516e-04</td>\n",
       "      <td>6.907142e-05</td>\n",
       "      <td>3.758727e-05</td>\n",
       "      <td>1.086593e-05</td>\n",
       "      <td>8.272128e-05</td>\n",
       "      <td>1.902035e-05</td>\n",
       "      <td>5.600410e-06</td>\n",
       "      <td>1.311913e-04</td>\n",
       "      <td>9.828466e-07</td>\n",
       "      <td>5.627621e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>1.722875e-03</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>5.912071e-06</td>\n",
       "      <td>6.228637e-06</td>\n",
       "      <td>1.577607e-05</td>\n",
       "      <td>1.095253e-05</td>\n",
       "      <td>3.482179e-05</td>\n",
       "      <td>1.270667e-05</td>\n",
       "      <td>2.673777e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.001421e-04</td>\n",
       "      <td>1.157864e-05</td>\n",
       "      <td>4.384114e-06</td>\n",
       "      <td>9.607608e-06</td>\n",
       "      <td>5.193697e-06</td>\n",
       "      <td>1.057694e-05</td>\n",
       "      <td>1.512679e-04</td>\n",
       "      <td>2.817611e-05</td>\n",
       "      <td>4.176721e-05</td>\n",
       "      <td>2.790090e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  000621fb3cbb32d8935728e48679680e   9.783715e-07      0.000003   \n",
       "1  00102ee9d8eb90812350685311fe5890   3.904235e-06      0.000003   \n",
       "2  0012a730dfa437f5f3613fb75efcd4ce   1.803103e-06      0.000169   \n",
       "3  001510bc8570bbeee98c8d80c8a95ec1   3.248847e-03      0.000033   \n",
       "4  001a5f3114548acdefa3d4da05474c2e   1.722875e-03      0.000998   \n",
       "\n",
       "   african_hunting_dog      airedale  american_staffordshire_terrier  \\\n",
       "0         1.773483e-07  1.623504e-07                    5.192971e-08   \n",
       "1         1.349749e-06  3.222111e-06                    2.799774e-06   \n",
       "2         2.591239e-06  6.032020e-06                    2.033924e-06   \n",
       "3         1.016343e-05  1.129691e-05                    1.574612e-03   \n",
       "4         5.912071e-06  6.228637e-06                    1.577607e-05   \n",
       "\n",
       "    appenzeller  australian_terrier       basenji        basset  ...  \\\n",
       "0  2.869335e-07        1.185932e-07  1.517987e-07  1.527176e-07  ...   \n",
       "1  3.205525e-06        2.429732e-06  2.776531e-06  1.035491e-06  ...   \n",
       "2  2.935269e-05        2.417689e-06  2.832639e-07  5.678557e-05  ...   \n",
       "3  2.237491e-04        3.482581e-06  8.029431e-05  5.339699e-05  ...   \n",
       "4  1.095253e-05        3.482179e-05  1.270667e-05  2.673777e-05  ...   \n",
       "\n",
       "     toy_poodle   toy_terrier        vizsla  walker_hound    weimaraner  \\\n",
       "0  3.058285e-07  6.149770e-07  2.052570e-07  1.845535e-07  2.013001e-07   \n",
       "1  1.178894e-05  9.557832e-07  2.354040e-06  1.257419e-06  1.265381e-06   \n",
       "2  6.179981e-07  4.658894e-06  4.792734e-06  1.388795e-04  6.675890e-05   \n",
       "3  1.736516e-04  6.907142e-05  3.758727e-05  1.086593e-05  8.272128e-05   \n",
       "4  2.001421e-04  1.157864e-05  4.384114e-06  9.607608e-06  5.193697e-06   \n",
       "\n",
       "   welsh_springer_spaniel  west_highland_white_terrier       whippet  \\\n",
       "0            3.922409e-07                 1.005067e-07  2.207841e-07   \n",
       "1            8.060605e-07                 5.633652e-05  1.393395e-06   \n",
       "2            8.983470e-03                 3.536553e-06  2.779912e-06   \n",
       "3            1.902035e-05                 5.600410e-06  1.311913e-04   \n",
       "4            1.057694e-05                 1.512679e-04  2.817611e-05   \n",
       "\n",
       "   wire-haired_fox_terrier  yorkshire_terrier  \n",
       "0             1.674841e-07       6.018194e-07  \n",
       "1             8.355050e-07       2.548201e-06  \n",
       "2             3.517055e-06       1.412737e-05  \n",
       "3             9.828466e-07       5.627621e-05  \n",
       "4             4.176721e-05       2.790090e-04  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f52a5b86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:02.082415Z",
     "iopub.status.busy": "2025-09-21T02:23:02.082172Z",
     "iopub.status.idle": "2025-09-21T02:23:04.166157Z",
     "shell.execute_reply": "2025-09-21T02:23:04.165594Z"
    },
    "papermill": {
     "duration": 2.117391,
     "end_time": "2025-09-21T02:23:04.167525",
     "exception": false,
     "start_time": "2025-09-21T02:23:02.050134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_sub.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8d84446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T02:23:04.232944Z",
     "iopub.status.busy": "2025-09-21T02:23:04.232211Z",
     "iopub.status.idle": "2025-09-21T02:23:04.236111Z",
     "shell.execute_reply": "2025-09-21T02:23:04.235628Z"
    },
    "papermill": {
     "duration": 0.037167,
     "end_time": "2025-09-21T02:23:04.237281",
     "exception": false,
     "start_time": "2025-09-21T02:23:04.200114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357\n"
     ]
    }
   ],
   "source": [
    "print(len(new_sub))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861871,
     "sourceId": 7327,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10517.087654,
   "end_time": "2025-09-21T02:23:06.926199",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-20T23:27:49.838545",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
